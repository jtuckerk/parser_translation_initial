{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Averaged perceptron classifier. Implementation geared for simplicity rather than\n",
    "efficiency.\n",
    "\"\"\"\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "\n",
    "class AveragedPerceptron(object):\n",
    "\n",
    "    '''An averaged perceptron, as implemented by Matthew Honnibal.\n",
    "    See more implementation details here:\n",
    "        http://honnibal.wordpress.com/2013/09/11/a-good-part-of-speechpos-tagger-in-about-200-lines-of-python/\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        # Each feature gets its own weight vector, so weights is a dict-of-dicts\n",
    "        self.weights = {}\n",
    "        self.classes = set()\n",
    "        # The accumulated values, for the averaging. These will be keyed by\n",
    "        # feature/clas tuples\n",
    "        self._totals = defaultdict(int)\n",
    "        # The last time the feature was changed, for the averaging. Also\n",
    "        # keyed by feature/clas tuples\n",
    "        # (tstamps is short for timestamps)\n",
    "        self._tstamps = defaultdict(int)\n",
    "        # Number of instances seen\n",
    "        self.i = 0\n",
    "\n",
    "    def predict(self, features):\n",
    "        '''Dot-product the features and current weights and return the best label.'''\n",
    "        scores = defaultdict(float)\n",
    "        \n",
    "        for feat, value in features.items():\n",
    "            \n",
    "            if feat not in self.weights or value == 0:\n",
    "                continue\n",
    "            weights = self.weights[feat]\n",
    "            for label, weight in weights.items():\n",
    "                scores[label] += value * weight\n",
    "        # Do a secondary alphabetic sort, for stability\n",
    "           \n",
    "        maxClass = max(self.classes, key=lambda label: (scores[label], label))\n",
    "        maxScore = scores[maxClass]\n",
    "        scores[maxClass] = 0\n",
    "        secondMaxClass = max(self.classes, key=lambda label: (scores[label], label))\n",
    "        secondMaxScore = scores[secondMaxClass]\n",
    "\n",
    "        return maxClass, maxScore-secondMaxScore\n",
    "\n",
    "    def update(self, truth, guess, features):\n",
    "        '''Update the feature weights.'''\n",
    "        def upd_feat(c, f, w, v):\n",
    "            param = (f, c)\n",
    "            self._totals[param] += (self.i - self._tstamps[param]) * w\n",
    "            self._tstamps[param] = self.i\n",
    "            self.weights[f][c] = w + v\n",
    "\n",
    "        self.i += 1\n",
    "        if truth == guess:\n",
    "            return None\n",
    "        for f in features:\n",
    "            weights = self.weights.setdefault(f, {})\n",
    "            upd_feat(truth, f, weights.get(truth, 0.0), 1.0)\n",
    "            upd_feat(guess, f, weights.get(guess, 0.0), -1.0)\n",
    "        return None\n",
    "\n",
    "    def average_weights(self):\n",
    "        '''Average weights from all iterations.'''\n",
    "        for feat, weights in self.weights.items():\n",
    "            new_feat_weights = {}\n",
    "            for clas, weight in weights.items():\n",
    "                param = (feat, clas)\n",
    "                total = self._totals[param]\n",
    "                total += (self.i - self._tstamps[param]) * weight\n",
    "                averaged = round(total / float(self.i), 3)\n",
    "                if averaged:\n",
    "                    new_feat_weights[clas] = averaged\n",
    "            self.weights[feat] = new_feat_weights\n",
    "        return None\n",
    "\n",
    "    def save(self, path):\n",
    "        '''Save the pickled model weights.'''\n",
    "        return pickle.dump(dict(self.weights), open(path, 'w'))\n",
    "\n",
    "    def load(self, path):\n",
    "        '''Load the pickled model weights.'''\n",
    "        self.weights = pickle.load(open(path))\n",
    "        return None\n",
    "\n",
    "\n",
    "def train(nr_iter, examples):\n",
    "    '''Return an averaged perceptron model trained on ``examples`` for\n",
    "    ``nr_iter`` iterations.\n",
    "    '''\n",
    "    model = AveragedPerceptron()\n",
    "    for i in range(nr_iter):\n",
    "        random.shuffle(examples)\n",
    "        for features, class_ in examples:\n",
    "            scores = model.predict(features)\n",
    "            guess, score = max(scores.items(), key=lambda i: i[1])\n",
    "            if guess != class_:\n",
    "                model.update(class_, guess, features)\n",
    "    model.average_weights()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import absolute_import\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "from textblob.base import BaseTagger\n",
    "from textblob.tokenizers import WordTokenizer, SentenceTokenizer\n",
    "from textblob.exceptions import MissingCorpusError\n",
    "\n",
    "\n",
    "PICKLE = \"trontagger-0.1.0.pickle\"\n",
    "\n",
    "\n",
    "class PerceptronTagger(BaseTagger):\n",
    "\n",
    "    '''Greedy Averaged Perceptron tagger, as implemented by Matthew Honnibal.\n",
    "    See more implementation details here:\n",
    "        http://honnibal.wordpress.com/2013/09/11/a-good-part-of-speechpos-tagger-in-about-200-lines-of-python/\n",
    "    :param load: Load the pickled model upon instantiation.\n",
    "    '''\n",
    "\n",
    "    START = ['-START-', '-START2-']\n",
    "    END = ['-END-', '-END2-']\n",
    "    #AP_MODEL_LOC = os.path.join(os.path.dirname(__file__), PICKLE)\n",
    "\n",
    "    def __init__(self, load=False):\n",
    "        self.model = AveragedPerceptron()\n",
    "        self.tagdict = {}\n",
    "        print \"oh hello there\"\n",
    "        self.classes = set()\n",
    "        if load:\n",
    "            self.load(self.AP_MODEL_LOC)\n",
    "\n",
    "    def tag(self, corpus, tokenize=True):\n",
    "        '''Tags a string `corpus`.'''\n",
    "        # Assume untokenized corpus has \\n between sentences and ' ' between words\n",
    "        s_split = SentenceTokenizer().tokenize if tokenize else lambda t: t.split('\\n')\n",
    "        w_split = WordTokenizer().tokenize if tokenize else lambda s: s.split()\n",
    "        def split_sents(corpus):\n",
    "            for s in s_split(corpus):\n",
    "                yield w_split(s)\n",
    "\n",
    "        print \"HEY HEY\"\n",
    "        prev, prev2 = self.START\n",
    "        tokens = []\n",
    "        for words in split_sents(corpus):\n",
    "            context = self.START + [self._normalize(w) for w in words] + self.END\n",
    "            for i, word in enumerate(words):\n",
    "                tag = None #self.tagdict.get(word)\n",
    "                if not tag:\n",
    "                    features = self._get_features(i, word, context, prev, prev2)\n",
    "                    tag, confidence = self.model.predict(features)\n",
    "                tokens.append((word, tag, confidence))\n",
    "                prev2 = prev\n",
    "                prev = tag\n",
    "        return tokens\n",
    "\n",
    "    def train(self, sentences, save_loc=None, nr_iter=5):\n",
    "        '''Train a model from sentences, and save it at ``save_loc``. ``nr_iter``\n",
    "        controls the number of Perceptron training iterations.\n",
    "        :param sentences: A list of (words, tags) tuples.\n",
    "        :param save_loc: If not ``None``, saves a pickled model in this location.\n",
    "        :param nr_iter: Number of training iterations.\n",
    "        '''\n",
    "        \"Hi train\"\n",
    "        self._make_tagdict(sentences)\n",
    "        self.model.classes = self.classes\n",
    "        prev, prev2 = self.START\n",
    "        for iter_ in range(nr_iter):\n",
    "            c = 0\n",
    "            n = 0\n",
    "            for words, tags in sentences:\n",
    "                context = self.START + [self._normalize(w) for w in words] \\\n",
    "                                                                    + self.END\n",
    "                for i, word in enumerate(words):\n",
    "                    guess = None #self.tagdict.get(word)\n",
    "                    if not guess:\n",
    "                        feats = self._get_features(i, word, context, prev, prev2)\n",
    "                        guess, confidence = self.model.predict(feats)\n",
    "                        self.model.update(tags[i], guess, feats)\n",
    "                    prev2 = prev\n",
    "                    prev = guess\n",
    "                    c += guess == tags[i]\n",
    "                    n += 1\n",
    "            random.shuffle(sentences)\n",
    "            logging.info(\"Iter {0}: {1}/{2}={3}\".format(iter_, c, n, _pc(c, n)))\n",
    "        self.model.average_weights()\n",
    "        # Pickle as a binary file\n",
    "        if save_loc is not None:\n",
    "            pickle.dump((self.model.weights, self.tagdict, self.classes),\n",
    "                         open(save_loc, 'wb'), -1)\n",
    "        return None\n",
    "\n",
    "    def load(self, loc):\n",
    "        '''Load a pickled model.'''\n",
    "        try:\n",
    "            w_td_c = pickle.load(open(loc, 'rb'))\n",
    "        except IOError:\n",
    "            msg = (\"Missing trontagger.pickle file.\")\n",
    "            raise MissingCorpusError(msg)\n",
    "        self.model.weights, self.tagdict, self.classes = w_td_c\n",
    "        self.model.classes = self.classes\n",
    "        return None\n",
    "\n",
    "    def _normalize(self, word):\n",
    "        '''Normalization used in pre-processing.\n",
    "        - All words are lower cased\n",
    "        - Digits in the range 1800-2100 are represented as !YEAR;\n",
    "        - Other digits are represented as !DIGITS\n",
    "        :rtype: str\n",
    "        '''\n",
    "        if '-' in word and word[0] != '-':\n",
    "            return '!HYPHEN'\n",
    "        elif word.isdigit() and len(word) == 4:\n",
    "            return '!YEAR'\n",
    "        elif word[0].isdigit():\n",
    "            return '!DIGITS'\n",
    "        else:\n",
    "            return word.lower()\n",
    "\n",
    "    def _get_features(self, i, word, context, prev, prev2):\n",
    "        '''Map tokens into a feature representation, implemented as a\n",
    "        {hashable: float} dict. If the features change, a new model must be\n",
    "        trained.\n",
    "        '''\n",
    "        def add(name, *args):\n",
    "            features[' '.join((name,) + tuple(args))] += 1\n",
    "\n",
    "        i += len(self.START)\n",
    "        features = defaultdict(int)\n",
    "        # It's useful to have a constant feature, which acts sort of like a prior\n",
    "        add('bias')\n",
    "        add('i suffix', word[-3:])\n",
    "        add('i pref1', word[0])\n",
    "        add('i-1 tag', prev)\n",
    "        add('i-2 tag', prev2)\n",
    "        add('i tag+i-2 tag', prev, prev2)\n",
    "        add('i word', context[i])\n",
    "        add('i-1 tag+i word', prev, context[i])\n",
    "        add('i-1 word', context[i-1])\n",
    "        add('i-1 suffix', context[i-1][-3:])\n",
    "        add('i-2 word', context[i-2])\n",
    "        add('i+1 word', context[i+1])\n",
    "        add('i+1 suffix', context[i+1][-3:])\n",
    "        add('i+2 word', context[i+2])\n",
    "        return features\n",
    "\n",
    "    def _make_tagdict(self, sentences):\n",
    "        '''Make a tag dictionary for single-tag words.'''\n",
    "        counts = defaultdict(lambda: defaultdict(int))\n",
    "        for words, tags in sentences:\n",
    "            for word, tag in zip(words, tags):\n",
    "                counts[word][tag] += 1\n",
    "                self.classes.add(tag)\n",
    "        freq_thresh = 20\n",
    "        ambiguity_thresh = 0.97\n",
    "        for word, tag_freqs in counts.items():\n",
    "            tag, mode = max(tag_freqs.items(), key=lambda item: item[1])\n",
    "            n = sum(tag_freqs.values())\n",
    "            # Don't add rare words to the tag dictionary\n",
    "            # Only add quite unambiguous words\n",
    "            if n >= freq_thresh and (float(mode) / n) >= ambiguity_thresh:\n",
    "                self.tagdict[word] = tag\n",
    "\n",
    "\n",
    "def _pc(n, d):\n",
    "    return (float(n) / d) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/local/lib/python2.7/site-packages/textblob/__init__.pyc'"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import textblob\n",
    "textblob.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainFile='/Users/tuckerkirven/Desktop/DR-Spring/Data/UD_Spanish/es-ud-train.conllu'\n",
    "testFile='/Users/tuckerkirven/Desktop/DR-Spring/Data/UD_Spanish/es-ud-test.conllu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28374"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### get training set from UD\n",
    "sentences_w_tags = []\n",
    "count = 0\n",
    "words=[]\n",
    "tags=[]\n",
    "for line in open(trainFile):\n",
    "\n",
    "    vals = line.split('\\t')\n",
    "    if (len(vals) > 1):\n",
    "        words.append(vals[1])\n",
    "        tags.append(vals[3])\n",
    "    else:\n",
    "        sentences_w_tags.append((words, tags))\n",
    "        words=[]\n",
    "        tags=[]\n",
    "len(sentences_w_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oh hello there\n"
     ]
    }
   ],
   "source": [
    "#Train\n",
    "pt = PerceptronTagger()\n",
    "#pt = NLTKTagger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pt.train(sentences_w_tags, nr_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from spacy.en import English, LOCAL_DATA_DIR\n",
    "data_dir = os.environ.get('SPACY_DATA', LOCAL_DATA_DIR)\n",
    "nlp = English(parser=False, entity=False, data_dir=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'English' object has no attribute 'default'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-742a6d6eb76b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'English' object has no attribute 'default'"
     ]
    }
   ],
   "source": [
    "dt = nlp.default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8676\n",
      "\n",
      " La construcciÃ³n d\n"
     ]
    }
   ],
   "source": [
    "#Get Test Corpus - \" \" seperated words \"\\n\" seperated sentences\n",
    "# and get list of correct tags\n",
    "corpus=\"\"\n",
    "words=[]\n",
    "test_correct_tags=[]\n",
    "for line in open(testFile):\n",
    "\n",
    "    vals = line.split('\\t')\n",
    "    if (len(vals) > 1):\n",
    "        words.append(vals[1])\n",
    "        test_correct_tags.append((vals[1],vals[3]))\n",
    "    else:\n",
    "        words.append(\"\\n\")\n",
    "print(len(words))\n",
    "#corpus=words\n",
    "corpus = \" \".join(words)\n",
    "print corpus[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEY HEY\n",
      "8128\n",
      "8128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('La', 'DET', 27.487000000000002)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output_tags = pt.tag(corpus, False)\n",
    "print(len(test_output_tags))\n",
    "print(len(test_correct_tags))\n",
    "test_output_tags[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8128\n",
      "average confidence of right = 23.9699401687\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'std_dev'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-338-c816d1ca9d09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf_right\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"average confidence of right = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf_right\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"stdev confidence of right = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd_dev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf_right\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"average confidence of wrong = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf_wrong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'std_dev'"
     ]
    }
   ],
   "source": [
    "import statistics as s\n",
    "correct = 0\n",
    "conf_right=[]\n",
    "conf_total =0\n",
    "conf_wrong=[]\n",
    "poss_total = len(test_output_tags)\n",
    "print poss_total\n",
    "unconfident_total = 0\n",
    "to_remove = []\n",
    "#for i in range(len(test_output_tags)):\n",
    "#    if (test_output_tags[i][2] <= 20):\n",
    "#        a=3#print (i, test_correct_tags[i], test_output_tags[i])\n",
    "#        to_remove.append(i)\n",
    "\n",
    "#for index in reversed(to_remove):\n",
    "#    del test_correct_tags[index]\n",
    "#    del test_output_tags[index]\n",
    "    \n",
    "for i in range(len(test_output_tags)):\n",
    "    if (test_correct_tags[i][1] == test_output_tags[i][1]):\n",
    "        conf_right.append(test_output_tags[i][2])\n",
    "        correct+=1\n",
    "    else:\n",
    "        conf_wrong.append(test_output_tags[i][2])\n",
    "a = np.array(conf_right)\n",
    "print \"average confidence of right = \" + str(s.mean(conf_right))\n",
    "print \"stdev confidence of right = \" + str(s.stdev(conf_right))\n",
    "\n",
    "print \"average confidence of wrong = \" + str(s.mean(conf_wrong))\n",
    "print \"stdev confidence of wrong = \" + str(s.stdev(conf_wrong))\n",
    "    \n",
    "accc = 100.00* (1.0*correct)/poss_total\n",
    "\n",
    "print  len(to_remove),poss_total\n",
    "print \"accuracy: \" + str(accc) + \"%\"\n",
    "print \"accuracy after cutoff\" + str(accc_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[93.449, 93.525, 93.7, 93.72, 93.7599]"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac = [(1,93.449), (2,93.525), (6,93.70), (8,93.72), (12,93.7599)]\n",
    "a = [i[0] for i in ac]\n",
    "b = [i[1] for i in ac]\n",
    "a\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x116c61f10>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEACAYAAAC+gnFaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118f43ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acc_id=\"AC5387d3c4597807d2de889091148d126c\"\n",
    "auth_tok=\"1639f28d728c5cd85dfcbd57d231c39c\"\n",
    "\n",
    "from twilio.rest import TwilioRestClient\n",
    " \n",
    "# Find these values at https://twilio.com/user/account\n",
    "account_sid = \"AC5387d3c4597807d2de889091148d126c\"\n",
    "auth_token = \"1639f28d728c5cd85dfcbd57d231c39c\"\n",
    "client = TwilioRestClient(account_sid, auth_token)\n",
    " \n",
    "message = client.messages.create(to=\"+15027949011\", from_=\"+1 502-354-4142\",\n",
    "                                     body=\"done: accuracry = \" + str(accc)+ \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
