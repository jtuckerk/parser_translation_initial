{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy Tagger implementation\n",
    "getting aroung 94% accuracy for english and spanish trained on UD data sets ~12,000 training sentence for english, ~7,000? sentences for spanish<br>\n",
    "need to check if I'm doing something wrong, or just need more training samples. Blog claims 97.something% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Averaged perceptron classifier. Implementation geared for simplicity rather than\n",
    "efficiency.\n",
    "\"\"\"\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "\n",
    "class AveragedPerceptron(object):\n",
    "\n",
    "    '''An averaged perceptron, as implemented by Matthew Honnibal.\n",
    "    See more implementation details here:\n",
    "        http://honnibal.wordpress.com/2013/09/11/a-good-part-of-speechpos-tagger-in-about-200-lines-of-python/\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        # Each feature gets its own weight vector, so weights is a dict-of-dicts\n",
    "        \n",
    "        self.weights = {}\n",
    "        self.classes = set()\n",
    "        # The accumulated values, for the averaging. These will be keyed by\n",
    "        # feature/clas tuples\n",
    "        self._totals = defaultdict(int)\n",
    "        # The last time the feature was changed, for the averaging. Also\n",
    "        # keyed by feature/clas tuples\n",
    "        # (tstamps is short for timestamps)\n",
    "        self._tstamps = defaultdict(int)\n",
    "        # Number of instances seen\n",
    "        self.i = 0\n",
    "\n",
    "    def predict(self, features, dont_allow):\n",
    "        '''Dot-product the features and current weights and return the best label.'''\n",
    "        scores = defaultdict(float)\n",
    "        \n",
    "        for feat, value in features.items():\n",
    "            \n",
    "            if feat not in self.weights or value == 0:\n",
    "                continue\n",
    "            weights = self.weights[feat]\n",
    "            for label, weight in weights.items():\n",
    "                scores[label] += value * weight\n",
    "        # Do a secondary alphabetic sort, for stability\n",
    "        sort_by_score = lambda d: (d[1], d)\n",
    "        \n",
    "        first_found=False\n",
    "        maxClass = \"None\"\n",
    "        maxScore = 0\n",
    "    \n",
    "        secondMaxClass = \"None\"\n",
    "        secondMaxScore = 0\n",
    "        \n",
    "        for label, score in sorted(scores.iteritems(), key=sort_by_score, reverse=True):\n",
    "            if(label != dont_allow and not first_found):\n",
    "                maxClass = label\n",
    "                maxScore = score\n",
    "                first_found=True\n",
    "            elif(label != dont_allow and first_found):\n",
    "                secondMaxClass = label\n",
    "                secondMaxScore = score\n",
    "                break\n",
    "      \n",
    "        return maxClass, maxScore-secondMaxScore\n",
    "\n",
    "    def update(self, truth, guess, features):\n",
    "        '''Update the feature weights.'''\n",
    "        def upd_feat(c, f, w, v):\n",
    "            param = (f, c)\n",
    "            self._totals[param] += (self.i - self._tstamps[param]) * w\n",
    "            self._tstamps[param] = self.i\n",
    "            self.weights[f][c] = w + v\n",
    "\n",
    "        self.i += 1\n",
    "        if truth == guess:\n",
    "            return None\n",
    "        for f in features:\n",
    "            weights = self.weights.setdefault(f, {})\n",
    "            upd_feat(truth, f, weights.get(truth, 0.0), 1.0)\n",
    "            upd_feat(guess, f, weights.get(guess, 0.0), -1.0)\n",
    "        return None\n",
    "\n",
    "    def average_weights(self):\n",
    "        '''Average weights from all iterations.'''\n",
    "        for feat, weights in self.weights.items():\n",
    "            new_feat_weights = {}\n",
    "            for clas, weight in weights.items():\n",
    "                param = (feat, clas)\n",
    "                total = self._totals[param]\n",
    "                total += (self.i - self._tstamps[param]) * weight\n",
    "                averaged = round(total / float(self.i), 3)\n",
    "                if averaged:\n",
    "                    new_feat_weights[clas] = averaged\n",
    "            self.weights[feat] = new_feat_weights\n",
    "        return None\n",
    "\n",
    "    def save(self, path):\n",
    "        '''Save the pickled model weights.'''\n",
    "        return pickle.dump(dict(self.weights), open(path, 'w'))\n",
    "\n",
    "    def load(self, path):\n",
    "        '''Load the pickled model weights.'''\n",
    "        self.weights = pickle.load(open(path))\n",
    "        return None\n",
    "\n",
    "\n",
    "def train(nr_iter, examples):\n",
    "    '''Return an averaged perceptron model trained on ``examples`` for\n",
    "    ``nr_iter`` iterations.\n",
    "    '''\n",
    "    model = AveragedPerceptron()\n",
    "    for i in range(nr_iter):\n",
    "        random.shuffle(examples)\n",
    "        for features, class_ in examples:\n",
    "            scores = model.predict(features)\n",
    "            guess, score = max(scores.items(), key=lambda i: i[1])\n",
    "            if guess != class_:\n",
    "                model.update(class_, guess, features)\n",
    "    model.average_weights()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import absolute_import\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "from textblob.tokenizers import WordTokenizer, SentenceTokenizer\n",
    "from textblob.exceptions import MissingCorpusError\n",
    "\n",
    "\n",
    "PICKLE = \"trontagger-0.1.0.pickle\"\n",
    "\n",
    "\n",
    "class PerceptronTagger(AveragedPerceptron):\n",
    "\n",
    "    '''Greedy Averaged Perceptron tagger, as implemented by Matthew Honnibal.\n",
    "    See more implementation details here:\n",
    "        http://honnibal.wordpress.com/2013/09/11/a-good-part-of-speechpos-tagger-in-about-200-lines-of-python/\n",
    "    :param load: Load the pickled model upon instantiation.\n",
    "    '''\n",
    "\n",
    "    START = ['-START-', '-START2-']\n",
    "    END = ['-END-', '-END2-']\n",
    "    #AP_MODEL_LOC = os.path.join(os.path.dirname(__file__), PICKLE)\n",
    "\n",
    "    def __init__(self, load=False):\n",
    "        self.model = AveragedPerceptron()\n",
    "        self.tagdict = {}\n",
    "        self.classes = set()\n",
    "        if load:\n",
    "            self.load(self.AP_MODEL_LOC)\n",
    "\n",
    "    def tag(self, corpus, tokenize=True, dont_allow=None):\n",
    "        '''Tags a string `corpus`.'''\n",
    "        # Assume untokenized corpus has \\n between sentences and ' ' between words\n",
    "        s_split = SentenceTokenizer().tokenize if tokenize else lambda t: t.split('\\n')\n",
    "        w_split = WordTokenizer().tokenize if tokenize else lambda s: s.split()\n",
    "        def split_sents(corpus):\n",
    "            for s in s_split(corpus):\n",
    "                yield w_split(s)\n",
    "\n",
    "        prev, prev2 = self.START\n",
    "        tokens = []\n",
    "        for words in split_sents(corpus):\n",
    "            sentence_tags = []\n",
    "            context = self.START + [self._normalize(w) for w in words] + self.END\n",
    "            for i, word in enumerate(words):\n",
    "                tag = None#self.tagdict.get(word)\n",
    "                confidence = 30\n",
    "                if not tag:\n",
    "                    features = self._get_features(i, word, context, prev, prev2)\n",
    "                    tag, confidence = self.model.predict(features, dont_allow)\n",
    "                sentence_tags.append((word, tag, confidence))\n",
    "                prev2 = prev\n",
    "                prev = tag\n",
    "            tokens.append(sentence_tags)\n",
    "        return tokens\n",
    "\n",
    "    def train(self, sentences, save_loc=None, nr_iter=5, dont_allow=None):\n",
    "        '''Train a model from sentences, and save it at ``save_loc``. ``nr_iter``\n",
    "        controls the number of Perceptron training iterations.\n",
    "        :param sentences: A list of (words, tags) tuples.\n",
    "        :param save_loc: If not ``None``, saves a pickled model in this location.\n",
    "        :param nr_iter: Number of training iterations.\n",
    "        '''\n",
    "        \"Hi train\"\n",
    "        self._make_tagdict(sentences)\n",
    "        self.model.classes = self.classes\n",
    "        prev, prev2 = self.START\n",
    "        for iter_ in range(nr_iter):\n",
    "            c = 0\n",
    "            n = 0\n",
    "            for words, tags in sentences:\n",
    "                context = self.START + [self._normalize(w) for w in words] \\\n",
    "                                                                    + self.END\n",
    "                for i, word in enumerate(words):\n",
    "                    guess = None # self.tagdict.get(word)\n",
    "                    confidence = 30\n",
    "                    if not guess:\n",
    "                        feats = self._get_features(i, word, context, prev, prev2)\n",
    "                        guess, confidence = self.model.predict(feats, dont_allow)\n",
    "                        self.model.update(tags[i], guess, feats)\n",
    "                    prev2 = prev\n",
    "                    prev = guess\n",
    "                    c += guess == tags[i]\n",
    "                    n += 1\n",
    "            random.shuffle(sentences)\n",
    "            logging.info(\"Iter {0}: {1}/{2}={3}\".format(iter_, c, n, _pc(c, n)))\n",
    "        self.model.average_weights()\n",
    "        # Pickle as a binary file\n",
    "        if save_loc is not None:\n",
    "            pickle.dump((self.model.weights, self.tagdict, self.classes),\n",
    "                         open(save_loc, 'wb'), -1)\n",
    "        return None\n",
    "\n",
    "    def load(self, loc):\n",
    "        '''Load a pickled model.'''\n",
    "        try:\n",
    "            w_td_c = pickle.load(open(loc, 'rb'))\n",
    "        except IOError:\n",
    "            msg = (\"Missing trontagger.pickle file.\")\n",
    "            raise MissingCorpusError(msg)\n",
    "        self.model.weights, self.tagdict, self.classes = w_td_c\n",
    "        self.model.classes = self.classes\n",
    "        return None\n",
    "\n",
    "    def _normalize(self, word):\n",
    "        '''Normalization used in pre-processing.\n",
    "        - All words are lower cased\n",
    "        - Digits in the range 1800-2100 are represented as !YEAR;\n",
    "        - Other digits are represented as !DIGITS\n",
    "        :rtype: str\n",
    "        '''\n",
    "        if '-' in word and word[0] != '-':\n",
    "            return '!HYPHEN'\n",
    "        elif word.isdigit() and len(word) == 4:\n",
    "            return '!YEAR'\n",
    "        elif word[0].isdigit():\n",
    "            return '!DIGITS'\n",
    "        else:\n",
    "            return word.lower()\n",
    "\n",
    "    def _get_features(self, i, word, context, prev, prev2):\n",
    "        '''Map tokens into a feature representation, implemented as a\n",
    "        {hashable: float} dict. If the features change, a new model must be\n",
    "        trained.\n",
    "        '''\n",
    "        def add(name, *args):\n",
    "            features[' '.join((name,) + tuple(args))] += 1\n",
    "\n",
    "        i += len(self.START)\n",
    "        features = defaultdict(int)\n",
    "        # It's useful to have a constant feature, which acts sort of like a prior\n",
    "        add('bias')\n",
    "        add('i suffix', word[-3:])\n",
    "        add('i pref1', word[0])\n",
    "        add('i-1 tag', prev)\n",
    "        add('i-2 tag', prev2)\n",
    "        add('i tag+i-2 tag', prev, prev2)\n",
    "        add('i word', context[i])\n",
    "        add('i-1 tag+i word', prev, context[i])\n",
    "        add('i-1 word', context[i-1])\n",
    "        add('i-1 suffix', context[i-1][-3:])\n",
    "        add('i-2 word', context[i-2])\n",
    "        add('i+1 word', context[i+1])\n",
    "        add('i+1 suffix', context[i+1][-3:])\n",
    "        add('i+2 word', context[i+2])\n",
    "        return features\n",
    "\n",
    "    def _make_tagdict(self, sentences):\n",
    "        \n",
    "        '''Make a tag dictionary for single-tag words.'''\n",
    "        counts = defaultdict(lambda: defaultdict(int))\n",
    "        for words, tags in sentences:\n",
    "            for word, tag in zip(words, tags):\n",
    "                counts[word][tag] += 1\n",
    "                self.classes.add(tag)\n",
    "        freq_thresh = 20\n",
    "        ambiguity_thresh = 0.97\n",
    "        for word, tag_freqs in counts.items():\n",
    "            tag, mode = max(tag_freqs.items(), key=lambda item: item[1])\n",
    "            n = sum(tag_freqs.values())\n",
    "            # Don't add rare words to the tag dictionary\n",
    "            # Only add quite unambiguous words\n",
    "            if n >= freq_thresh and (float(mode) / n) >= ambiguity_thresh:\n",
    "                self.tagdict[word] = tag\n",
    "\n",
    "\n",
    "def _pc(n, d):\n",
    "    return (float(n) / d) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions: setup, alignment mapping, test/check...etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_corpus_to_sentence_list(corpus):\n",
    "    sentence_list=[]\n",
    "    for sentence in corpus.split(\"\\n\"):\n",
    "        sentence_list.append(sentence.split(\" \"))\n",
    "    return sentence_list\n",
    "\n",
    "def convert_sentence_list_no_tags_to_corpus(sentence_list):\n",
    "    return \"\".join(\" \".join(x) for x in sentence_list)\n",
    "    \n",
    "def convert_tagged_to_train_format(tagged_sent_list):\n",
    "    train_list = []\n",
    "    for sent in tagged_sent_list:\n",
    "        words=[]\n",
    "        tags=[]\n",
    "        for tup in sent:\n",
    "            words.append(tup[0])\n",
    "            tags.append(tup[1])\n",
    "        train_list.append((words,tags))\n",
    "    return train_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### get training set from UD\n",
    "def load_tagged_sentences(file_name):\n",
    "    sentences_w_tags = []\n",
    "    count = 0\n",
    "    words=[]\n",
    "    tags=[]\n",
    "    on_sentence = False\n",
    "    for line in open(trainFile):\n",
    "    \n",
    "        vals = line.split('\\t')\n",
    "        if (len(vals) > 1):\n",
    "            on_sentence = True\n",
    "            words.append(vals[1])\n",
    "            tags.append(vals[3])\n",
    "        elif (on_sentence):\n",
    "            on_sentence=False\n",
    "            sentences_w_tags.append((words, tags))\n",
    "            words=[]\n",
    "            tags=[]\n",
    "    \n",
    "    return sentences_w_tags # [ ([\"word\", \"word\", \"word\"], [\"tag\", \"tag\", \"tag\"]), next sentece...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#args sentences_with_tags = [ ([\"word\", \"word\", \"word\"], [\"tag\", \"tag\", \"tag\"]), next sentece...]\n",
    "def train_tagger(tagger, sentences_with_tags, num_iters=5):\n",
    "    print str(len(sentences_with_tags)) + \" training sentences\"\n",
    "    print str(num_iters) + \" training interations\"\n",
    "    tagger.train(sentences_with_tags, nr_iter=num_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# return arg1 sentences with word/tokens seperated by a \" \" and sentences seperated by \"\\n\" \n",
    "# return arg2 word with tag tuple list\n",
    "def get_test_corpus(file_name):\n",
    "    corpus=\"\"\n",
    "    words=[]\n",
    "    test_correct_tags=[]\n",
    "    sentence_tags = []\n",
    "    sentence_count = 0\n",
    "    on_sentence = False\n",
    "    for line in open(file_name):\n",
    "\n",
    "        vals = line.split('\\t')\n",
    "        if (len(vals) > 1):\n",
    "            on_sentence=True\n",
    "            words.append(vals[1])\n",
    "            sentence_tags.append((vals[1],vals[3]))\n",
    "        elif(on_sentence):\n",
    "            sentence_count +=1\n",
    "            on_sentence = False\n",
    "            words.append(\"\\n\")\n",
    "            test_correct_tags.append(sentence_tags)\n",
    "            sentence_tags = []\n",
    "\n",
    "\n",
    "    corpus = \" \".join(words)\n",
    "    print str(sentence_count) + \" sentences in test corpus\"\n",
    "    return corpus, test_correct_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#expects corpus in the same form as get test corpus returns as arg1\n",
    "# returns list [\"word\", \"tag\", float_confidence]\n",
    "def tag_tagger(tagger, corpus, dont_allow=None):\n",
    "    return tagger.tag(corpus, False, dont_allow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statistics as s\n",
    "import copy\n",
    "\n",
    "#todo get accuracy of tags above certain min_confidence_threshold\n",
    "def analyze_tags(guess_tags, correct_tags, show_full=False, sort_key=lambda ((key_right,key_wrong), value): value):\n",
    "    correct_tag_type ={}\n",
    "    wrong_tag_type = {}\n",
    "    \n",
    "    conf_right = []\n",
    "    conf_wrong = []\n",
    "    \n",
    "    total_tags = 0\n",
    "    total_wrong_tags = 0\n",
    "    \n",
    "    total_sentences = len(guess_tags)\n",
    "    total_wrong_sent = 0\n",
    "    \n",
    "    for sent_num, correct_sentence in enumerate(correct_tags):\n",
    "\n",
    "        perfect_sentence = True\n",
    "        for word_idx, word_tag_tuple in enumerate(correct_sentence):\n",
    "            guess_tuple = guess_tags[sent_num][word_idx]\n",
    "            word = guess_tuple[0]\n",
    "            tag_guess = guess_tuple[1]\n",
    "            guess_confidence = guess_tuple[2]\n",
    "            total_tags +=1\n",
    "            \n",
    "            if(word_tag_tuple[1] != tag_guess):\n",
    "                total_wrong_tags +=1\n",
    "                conf_wrong.append(guess_confidence)\n",
    "                perfect_sentence = False\n",
    "                error_tuple = (word_tag_tuple[1], tag_guess)\n",
    "                wrong_tag_type[error_tuple] = wrong_tag_type.get(error_tuple, 0) + 1\n",
    "            else:\n",
    "                correct_tag_type[tag_guess] = correct_tag_type.get(tag_guess, 0) + 1\n",
    "                conf_right.append(guess_confidence)\n",
    "                \n",
    "        if not perfect_sentence:\n",
    "            total_wrong_sent+= 1\n",
    "    \n",
    "    if(show_full):\n",
    "        for tag_tup, count in sorted(wrong_tag_type.iteritems(),key=sort_key):\n",
    "            print \"correct:\\t\"+tag_tup[0]+\"\\tincorrect:\\t\"+tag_tup[1]+\"\\tcount:\\t\"+str(count)\n",
    "    print total_wrong_sent, total_sentences\n",
    "    \n",
    "    if(len(conf_right) >0 and len(conf_wrong)>0): \n",
    "        print \"average confidence of right = \" + str(s.mean(conf_right))\n",
    "        print \"average confidence of wrong = \" + str(s.mean(conf_wrong))\n",
    "        print \"stdev confidence of right = \" + str(s.stdev(conf_right))\n",
    "        print \"stdev confidence of wrong = \" + str(s.stdev(conf_wrong))\n",
    "   \n",
    "    word_acc = (100.00*(total_tags-total_wrong_tags))/total_tags\n",
    "    sentence_acc = (100.00*(total_sentences-total_wrong_sent))/total_sentences\n",
    "\n",
    "    \n",
    "    print \"token accuracy: \" + str(word_acc) + \"%\"\n",
    "    print \"sentence accuracy: \" + str(sentence_acc) + \"%\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loads src and target original documents and loads alignments into list of tuples\n",
    "def get_alignment_info(source_file, tgt_file, align_file, num_matches=1000):\n",
    "    sentence_word_mappings =[]\n",
    "    orig_sentences = []\n",
    "    target_sentences= []\n",
    "    total=0\n",
    "    matches=0\n",
    "\n",
    "    from itertools import izip\n",
    "\n",
    "    with open(align_file) as align, open(source_file) as orig, open(tgt_file) as tgt: \n",
    "        for x, y, z in izip(align, orig, tgt):\n",
    "        \n",
    "            pairings = []\n",
    "            for pair in x.split(\" \"):\n",
    "                indexs = pair.split(\"-\")\n",
    "                if(len(indexs) <=1 or (indexs[0] == \"\" or indexs[1] == \"\")):\n",
    "                    continue\n",
    "                pairings.append((int(indexs[0]), int(indexs[1])))\n",
    "            src_tokens = y.split(\" \")\n",
    "            tgt_tokens = z.split(\" \")\n",
    "            \n",
    "            if (not filter_alignments(src_tokens, tgt_tokens, pairings)):\n",
    "                sentence_word_mappings.append(pairings)\n",
    "                orig_sentences.append(src_tokens)\n",
    "                target_sentences.append(tgt_tokens)\n",
    "                matches+=1\n",
    "         \n",
    "            total +=1\n",
    "            if matches>num_matches:\n",
    "                break\n",
    "    print  str((100.0*matches)/total) + \"% left after filter. \"+ str(matches) + \" found after filter\"\n",
    "    return orig_sentences, target_sentences, sentence_word_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#some sort of check to see if the alignment is \"good\" enough, filters if not\n",
    "def filter_alignments(src_sent_list, tgt_sent_list, align_pairing_list):\n",
    "    #dont filter any sentences\n",
    "    #return False\n",
    "    \n",
    "    #filter if length of the target and source are different or if the source and pairings lengths dont match\n",
    "    #return not (len(src_sent_list) == len(tgt_sent_list) or len(src_sent_list) == len(align_pairing_list))\n",
    "    \n",
    "    #filter if there are n fewer pairings than words in the target sentence\n",
    "    n=1\n",
    "    return len(tgt_sent_list)-n > len(align_pairing_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "untagged_tag_str = \"NOTAG\"\n",
    "#create a sentence list for training from tagged source language file and maps using alignments to the target language\n",
    "def map_tags(tagged_src, untagged_tgt, alignment_list):\n",
    "    tagged_tgt =[]\n",
    "    for sentence in untagged_tgt:\n",
    "        sent_tag_tuple_list = []\n",
    "        for word in sentence:\n",
    "            sent_tag_tuple_list.append((word, untagged_tag_str))\n",
    "        tagged_tgt.append(sent_tag_tuple_list)\n",
    "            \n",
    "    for sent_num, pairings in enumerate(alignment_list):\n",
    "        for pair in pairings:\n",
    "            src_tag_idx = pair[0]\n",
    "            tgt_tag_idx = pair[1]\n",
    "            \n",
    "            \n",
    "            tagged_tgt[sent_num][tgt_tag_idx] = tagged_src[sent_num][src_tag_idx]\n",
    "            \n",
    "    return tagged_tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "untagged_tag_str = \"NOTAG\"\n",
    "\n",
    "#english\n",
    "en_train_file='../Data/UD_English/en-ud-train.conllu'\n",
    "en_test_file='../Data/UD_English/en-ud-test.conllu'\n",
    "\n",
    "#spanish\n",
    "es_train_file='../Data/UD_Spanish/es-ud-train.conllu'\n",
    "es_test_file='../Data/UD_Spanish/es-ud-test.conllu'\n",
    "\n",
    "#arabic...\n",
    "\n",
    "trainFile=en_train_file\n",
    "testFile=en_test_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load, Train and Test source tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "src_language_train_data = load_tagged_sentences(trainFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12543 training sentences\n",
      "5 training interations\n"
     ]
    }
   ],
   "source": [
    "src_language_tagger = PerceptronTagger()\n",
    "train_tagger(src_language_tagger, src_language_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "src_language_init_test_data, src_test_sentence_w_correct_tags = get_test_corpus(testFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "src_guess_test_tags = tag_tagger(src_language_tagger, src_language_init_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "866 2078\n",
      "average confidence of right = 21.1111540364\n",
      "average confidence of wrong = 6.08250151791\n",
      "stdev confidence of right = 9.25918093899\n",
      "stdev confidence of wrong = 5.39933519814\n",
      "token accuracy: 93.4372011476%\n",
      "sentence accuracy: 58.3253128008%\n"
     ]
    }
   ],
   "source": [
    "# results\n",
    "analyze_tags(src_guess_test_tags, src_test_sentence_w_correct_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src_text_file = \"../Data/UN/c.true.en\"\n",
    "tgt_text_file = \"../Data/UN/c.true.es\"\n",
    "align_file = \"../Data/UN/aligned.intersect\"\n",
    "num_sents = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get alignments (do some filtering), tag source language, map to target language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match percentage: 9.05879795674\n"
     ]
    }
   ],
   "source": [
    "src_sent_list, tgt_sent_list, alignments_list = get_alignment_info(src_text_file, tgt_text_file, align_file, num_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tagged_source = tag_tagger(src_language_tagger, convert_sentence_list_no_tags_to_corpus(src_sent_list))\n",
    "untagged_target = tgt_sent_list\n",
    "tagged_target_data = map_tags(tagged_source, untagged_target, alignments_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train target language tagger on alignment tagged data, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_language_tagger = PerceptronTagger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_tagger(target_language_tagger, convert_tagged_to_train_format(tagged_target_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274 sentences in test corpus\n",
      "274 275\n",
      "average confidence of right = 10.5398614364\n",
      "average confidence of wrong = 3.68073571685\n",
      "stdev confidence of right = 8.11162874412\n",
      "stdev confidence of wrong = 4.35590052178\n",
      "token accuracy: 31.5206692913%\n",
      "sentence accuracy: 0.363636363636%\n"
     ]
    }
   ],
   "source": [
    "tgt_language_test_data, tgt_test_sentence_w_correct_tags = get_test_corpus(es_test_file)\n",
    "tgt_guess_test_tags = tag_tagger(target_language_tagger, tgt_language_test_data)\n",
    "\n",
    "sort_by_right = lambda ((key_right,key_wrong), value): key_right\n",
    "sort_by_wrong = lambda ((key_right,key_wrong), value): key_wrong\n",
    "sort_by_count = lambda ((key_right,key_wrong), value): value\n",
    "analyze_tags(tgt_guess_test_tags, tgt_test_sentence_w_correct_tags, False, sort_by_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Notes - Bad accuracies so far \n",
    "1000 sentence intermediate yielded 34.9 - no alignment filter - intersect alignment <br>\n",
    "10,000 sentence intermediate yielded 32.4% - no alignment filter - intersect alignment <br>\n",
    "1000 sentence intermediate - filter alignments if != length or source length != alignment_length 32.2% <br>\n",
    "1000 sentence intermediate - filter sentences with a difference in tokens and alignments > n=2 34% <br>\n",
    "1000 sentence intermediate - filter sentences with a difference in tokens and alignments > n=1 29% <br>\n",
    "5000 sentence intermediate - filter sentences with a difference in tokens and alignments > n=1 31.5% <br>\n",
    "not very promising results. Need to test out different alignments and filters <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English Tagger Generated from English Tagged Data\n",
    "### To see how well this should work with perfect alignments\n",
    "#### 78% accuracy - down from 93.5% - See below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5002 training sentences\n",
      "5 training interations\n",
      "2077 sentences in test corpus\n",
      "1717 2078\n",
      "average confidence of right = 13.8545315177\n",
      "average confidence of wrong = 5.00049252915\n",
      "stdev confidence of right = 7.70397296331\n",
      "stdev confidence of wrong = 4.74271481971\n",
      "token accuracy: 78.1319732228%\n",
      "sentence accuracy: 17.3724735322%\n"
     ]
    }
   ],
   "source": [
    "en_to_en_tagger = PerceptronTagger()\n",
    "train_tagger(en_to_en_tagger, convert_tagged_to_train_format(tagged_source))\n",
    "en_to_en_test_data, en_to_en_test_sentence_w_correct_tags = get_test_corpus(en_test_file)\n",
    "en_to_en_guess_test_tags = tag_tagger(en_to_en_tagger, en_to_en_test_data)\n",
    "\n",
    "analyze_tags(en_to_en_guess_test_tags, en_to_en_test_sentence_w_correct_tags, False, sort_by_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
